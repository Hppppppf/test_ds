<link rel="stylesheet" href="https://res.wx.qq.com/open/libs/weui/2.4.4/weui.min.css">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,minimum-scale=1.0,user-scalable=no">

<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
    <title>江苏电信云省分DeepSeek推理算力部署计算器</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <h1>江苏电信云省分DeepSeek推理算力部署计算器</h1>
		<h2>update <font color=red>20250225</font></h2>
<br />
        <div class="input-section">
            <label for="model-type">模型类型:</label>
            <select id="model-type">
                <option value="r1_671b">DeepSeek R1/V3 671B</option>
                <option value="r1_1.5b">DeepSeek R1 1.5B (蒸馏)</option>
                <option value="r1_7b">DeepSeek R1 7B (蒸馏)</option>
                <option value="r1_8b">DeepSeek R1 8B (蒸馏)</option>
                <option value="r1_14b">DeepSeek R1 14B (蒸馏)</option>
                <option value="r1_32b">DeepSeek R1 32B (蒸馏)</option>
                <option value="r1_70b">DeepSeek R1 70B (蒸馏)</option>
            </select>
        </div>

        <div class="input-section">
            <label for="precision">参数精度:</label>
            <select id="precision">
                <option value="fp16">FP16</option>
                <option value="fp8">FP8</option>
                <option value="bf16">BF16</option>
                <option value="int8">INT8</option>
                <option value="int4">INT4</option>
            </select>
        </div>

        <div class="input-section">
            <label for="concurrency">并发数:</label>
            <input type="number" id="concurrency" value="1" min="1">
        </div>

        <div class="input-section">
            <label for="context-length">上下文长度 (Token数):</label>
            <select id="context-length">
                <option value="4096">4K (4096)</option>
                <option value="8192" selected>8K (8192)</option>
                <option value="32768">32K (32768)</option>
                <option value="65536">64K (65536)</option>
            </select>
        </div>

        <div class="input-section">
            <label for="framework">推理框架 (影响性能，显存管理):</label>
            <select id="framework">
                <option value="auto">自动/通用 (简化估算)</option>
                <option value="vllm">vLLM (高性能)</option>
                <option value="llama_cpp">llama.cpp (CPU/GPU混合)</option>
                <option value="mindspore">MindSpore (华为昇腾)</option>
                <!-- 可以根据实际情况添加更多框架 -->
            </select>
        </div>

        <div class="input-section">
            <label for="fine-tuning-method">微调方法:</label>
            <select id="fine-tuning-method">
                <option value="inference">推理 (Inference)</option>
                <option value="lora">LoRA 微调</option>
                <!-- 未来可以添加 "全参数微调" 等选项，如果用户提供公式 -->
            </select>
        </div>

        <div class="input-section" id="lora-params-section" style="display: none;">
            <label for="lora-trainable-params">LoRA 可训练参数 (Billion):</label>
            <input type="number" id="lora-trainable-params" value="0" min="0" step="0.1">
        </div>

        <div class="input-section">
            <label for="hardware">算力卡:</label>
            <select id="hardware">
                <option value="ascend910b">华为昇腾910B</option>
                <option value="nvidia_h20">NVIDIA H20</option>
                <option value="nvidia_h800">NVIDIA H800</option>
                <option value="nvidia_a800">NVIDIA A800</option>
                <option value="nvidia_l40s">NVIDIA L40S</option>
                <option value="nvidia_a10">NVIDIA A10</option>
                <option value="nvidia_rtx4090">NVIDIA RTX 4090</option>
                <option value="nvidia_a100_40g">NVIDIA A100-40G</option>

            </select>
        </div>

        <button class="weui-btn weui-btn_primary" id="calculate-button">计算算力需求</button>

        <div id="results" class="results-section">
            <!-- 计算结果将显示在这里 -->
        </div>
    </div>

	      </a></span><span role="presentation" class="el-breadcrumb__separator"></span></span><span class="el-breadcrumb__item" data-v-64743607><span role="link" class="el-breadcrumb__inner"><a href="/document/10026730/10955481" class="breadcrumb-link" data-v-64743607>
          GPU云主机/弹性云主机：零基础搭建DeepSeek云端环境指南
        </a></span><span role="presentation" class="el-breadcrumb__separator"></span></span><span class="el-breadcrumb__item" data-v-64743607><span role="link" class="el-breadcrumb__inner"><a href="/document/10026730/10955476" aria-current="page" class="breadcrumb-link nuxt-link-exact-active nuxt-link-active" data-v-64743607>
          在天翼云使用Ollama运行DeepSeek的最佳实践-7B等版本
        </a></span><span role="presentation" class="el-breadcrumb__separator"></span></span></div></div></div> <div class="wrap search-common" data-v-7eb3ad9a data-v-1232ed39><div class="outter-input" data-v-7eb3ad9a><div class="input el-input el-input--suffix" data-v-7eb3ad9a><!----><input type="text" autocomplete="off" placeholder="请输入文档关键词搜索" class="el-input__inner"><!----><span class="el-input__suffix"><span class="el-input__suffix-inner"><i class="el-icon-search" data-v-7eb3ad9a></i><!----><!----><!----><!----></span><!----></span><!----><!----></div></div></div> <!----> <div class="sub-head" data-v-1232ed39><div data-v-1232ed39><div class="title" data-v-1232ed39>在天翼云使用Ollama运行DeepSeek的最佳实践-7B等版本</div> <div clearfix class="tools-wap view-wap" data-v-1232ed39><span class="time" data-v-1232ed39>
              更新时间 2025-02-22 17:46:38
            </span> <div class="share" data-v-2ed5a48c data-v-1232ed39><svg width="14" height="14" viewBox="0 0 14 14" fill="black" xmlns="http://www.w3.org/2000/svg" class="icon view-pc" data-v-2ed5a48c><path d="M10.5098 9.61883C10.0229 9.61883 9.58081 9.82108 9.26332 10.1433L5.03722 7.79622C5.16186 7.55634 5.23712 7.28824 5.23712 6.99897C5.23712 6.82729 5.20419 6.66502 5.15951 6.50745L9.32447 3.92052C9.6349 4.20038 10.0418 4.37441 10.4886 4.37441C11.4528 4.37441 12.2383 3.58893 12.2383 2.62471C12.2383 1.66049 11.4528 0.875 10.4886 0.875C9.52437 0.875 8.73888 1.66049 8.73888 2.62471C8.73888 2.82461 8.77886 3.01275 8.84 3.19148L4.71267 5.75254C4.39754 5.44211 3.96482 5.24691 3.48506 5.24691C2.52084 5.24691 1.73535 6.0324 1.73535 6.99662C1.73535 7.96084 2.52084 8.74633 3.48506 8.74633C3.83547 8.74633 4.16236 8.6405 4.43517 8.46176L8.82589 10.9005C8.78356 11.051 8.75534 11.2039 8.75534 11.3662C8.75534 12.3304 9.54083 13.1159 10.505 13.1159C11.4693 13.1159 12.2548 12.3304 12.2548 11.3662C12.2548 10.402 11.474 9.61883 10.5098 9.61883ZM10.4886 1.74985C10.9707 1.74985 11.3634 2.1426 11.3634 2.62471C11.3634 3.10682 10.9707 3.49956 10.4886 3.49956C10.0065 3.49956 9.61373 3.10682 9.61373 2.62471C9.61373 2.1426 10.0065 1.74985 10.4886 1.74985ZM2.61256 6.99897C2.61256 6.51686 3.0053 6.12412 3.48741 6.12412C3.96952 6.12412 4.36226 6.51686 4.36226 6.99897C4.36226 7.48108 3.96952 7.87382 3.48741 7.87382C3.0053 7.87382 2.61256 7.48108 2.61256 6.99897ZM10.5098 12.2434C10.0276 12.2434 9.6349 11.8506 9.6349 11.3685C9.6349 10.8864 10.0276 10.4937 10.5098 10.4937C10.9919 10.4937 11.3846 10.8864 11.3846 11.3685C11.3846 11.853 10.9919 12.2434 10.5098 12.2434Z" data-v-2ed5a48c></path></svg> <i class="icon-share view-wap" data-v-2ed5a48c></i> <!----> <div class="share-slider" data-v-2ed5a48c><ul data-v-2ed5a48c><li title="分享文档到微博" data-v-2ed5a48c><svg width="200px" height="179.96px" fill="#cdcdcd" viewBox="0 0 1138 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" class="icon" data-v-2ed5a48c><path d="M914.432 518.144q27.648 21.504 38.912 51.712t9.216 62.976-14.336 65.536-31.744 59.392q-34.816 48.128-78.848 81.92t-91.136 56.32-94.72 35.328-89.6 18.944-75.264 7.68-51.712 1.536-49.152-2.56-68.096-10.24-78.336-21.504-79.872-36.352-74.24-55.296-59.904-78.848q-16.384-29.696-22.016-63.488t-5.632-86.016q0-22.528 7.68-51.2t27.136-63.488 53.248-75.776 86.016-90.112q51.2-48.128 105.984-85.504t117.248-57.856q28.672-10.24 63.488-11.264t57.344 11.264q10.24 11.264 19.456 23.04t12.288 29.184q3.072 14.336 0.512 27.648t-5.632 26.624-5.12 25.6 2.048 22.528q17.408 2.048 33.792-1.536t31.744-9.216 31.232-11.776 33.28-9.216q27.648-5.12 54.784-4.608t49.152 7.68 36.352 22.016 17.408 38.4q2.048 14.336-2.048 26.624t-8.704 23.04-7.168 22.016 1.536 23.552q3.072 7.168 14.848 13.312t27.136 12.288 32.256 13.312 29.184 16.384zM656.384 836.608q26.624-16.384 53.76-45.056t44.032-64 18.944-75.776-20.48-81.408q-19.456-33.792-47.616-57.344t-62.976-37.376-74.24-19.968-80.384-6.144q-78.848 0-139.776 16.384t-105.472 43.008-72.192 60.416-38.912 68.608q-11.264 33.792-6.656 67.072t20.992 62.976 42.496 53.248 57.856 37.888q58.368 25.6 119.296 32.256t116.224 0.512 100.864-21.504 74.24-33.792zM522.24 513.024q20.48 8.192 38.912 18.432t32.768 27.648q10.24 12.288 17.92 30.72t10.752 39.424 1.536 42.496-9.728 38.912q-8.192 18.432-19.968 37.376t-28.672 35.328-40.448 29.184-57.344 18.944q-61.44 11.264-117.76-11.264t-88.064-74.752q-12.288-39.936-13.312-70.656t16.384-66.56q13.312-27.648 40.448-51.712t62.464-38.912 75.264-17.408 78.848 12.8zM359.424 764.928q37.888 3.072 57.856-18.432t21.504-48.128-15.36-47.616-52.736-16.896q-27.648 3.072-43.008 23.552t-17.408 43.52 9.728 42.496 39.424 21.504zM778.24 6.144q74.752 0 139.776 19.968t113.664 57.856 76.288 92.16 27.648 122.88q0 33.792-16.384 50.688t-35.328 17.408-35.328-14.336-16.384-45.568q0-40.96-22.528-77.824t-59.392-64.512-84.48-43.52-96.768-15.872q-31.744 0-47.104-15.36t-14.336-34.304 18.944-34.304 51.712-15.36zM778.24 169.984q95.232 0 144.384 48.64t49.152 146.944q0 30.72-10.24 43.52t-22.528 11.264-22.528-14.848-10.24-35.84q0-60.416-34.816-96.256t-93.184-35.84q-19.456 0-28.672-10.752t-9.216-23.04 9.728-23.04 28.16-10.752z" data-v-2ed5a48c></path></svg> <!----> <!----> <span class="label" data-v-2ed5a48c>新浪微博</span> <!----></li><li title="" data-v-2ed5a48c><!----> <svg t="1654592149516" fill="#cdcdcd" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6040" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200" class="icon" data-v-2ed5a48c><path d="M664.250054 368.541681c10.015098 0 19.892049 0.732687 29.67281 1.795902-26.647917-122.810047-159.358451-214.077703-310.826188-214.077703-169.353083 0-308.085774 114.232694-308.085774 259.274068 0 83.708494 46.165436 152.460344 123.281791 205.78483l-30.80868 91.730191 107.688651-53.455469c38.558178 7.53665 69.459978 15.308661 107.924012 15.308661 9.66308 0 19.230993-0.470721 28.752858-1.225921-6.025227-20.36584-9.521864-41.723264-9.521864-63.862493C402.328693 476.632491 517.908058 368.541681 664.250054 368.541681zM498.62897 285.87389c23.200398 0 38.557154 15.120372 38.557154 38.061874 0 22.846334-15.356756 38.156018-38.557154 38.156018-23.107277 0-46.260603-15.309684-46.260603-38.156018C452.368366 300.994262 475.522716 285.87389 498.62897 285.87389zM283.016307 362.090758c-23.107277 0-46.402843-15.309684-46.402843-38.156018 0-22.941502 23.295566-38.061874 46.402843-38.061874 23.081695 0 38.46301 15.120372 38.46301 38.061874C321.479317 346.782098 306.098002 362.090758 283.016307 362.090758zM945.448458 606.151333c0-121.888048-123.258255-221.236753-261.683954-221.236753-146.57838 0-262.015505 99.348706-262.015505 221.236753 0 122.06508 115.437126 221.200938 262.015505 221.200938 30.66644 0 61.617359-7.609305 92.423993-15.262612l84.513836 45.786813-23.178909-76.17082C899.379213 735.776599 945.448458 674.90216 945.448458 606.151333zM598.803483 567.994292c-15.332197 0-30.807656-15.096836-30.807656-30.501688 0-15.190981 15.47546-30.477129 30.807656-30.477129 23.295566 0 38.558178 15.286148 38.558178 30.477129C637.361661 552.897456 622.099049 567.994292 598.803483 567.994292zM768.25071 567.994292c-15.213493 0-30.594809-15.096836-30.594809-30.501688 0-15.190981 15.381315-30.477129 30.594809-30.477129 23.107277 0 38.558178 15.286148 38.558178 30.477129C806.808888 552.897456 791.357987 567.994292 768.25071 567.994292z" p-id="6041" data-v-2ed5a48c></path></svg> <!----> <span class="label" data-v-2ed5a48c>微信</span> <div class="qrcode" data-v-2ed5a48c><div class="note" data-v-2ed5a48c>扫码分享</div> <canvas id="qrcodeCanvas" class="can" data-v-2ed5a48c></canvas> <span class="arrow" data-v-2ed5a48c></span></div></li><li title="复制链接到剪贴板" data-v-2ed5a48c><!----> <!----> <svg fill="#cdcdcd" width="200px" height="200.00px" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" class="icon" data-v-2ed5a48c><path d="M752.535797 273.701662l-2.230808-2.227738c-51.299363-51.300386-135.227868-51.300386-186.526207 0l-118.846782 118.883621c-51.299363 51.281967-51.299363 135.222751 0 186.544627l2.192945 2.156106c4.27742 4.267187 8.833179 8.116865 13.485129 11.728112l43.49563-43.544749c-5.086855-2.956332-9.885138-6.591115-14.223956-10.92891l-2.192945-2.156106c-27.855418-27.866674-27.855418-73.180719 0-101.048417L606.609263 314.26859c27.782763-27.855418 73.084529-27.855418 100.951203 0l2.218528 2.180666c27.855418 27.867698 27.855418 73.194022 0 101.012601l-53.736878 53.765531c9.304923 23.067368 13.740956 47.64002 13.304004 72.114434l83.152838-83.117023C803.83516 408.918273 803.83516 325.004095 752.535797 273.701662L752.535797 273.701662 752.535797 273.701662 752.535797 273.701662zM576.877101 444.959118c-4.266164-4.264117-8.820899-8.118911-13.521968-11.680017l-43.472094 43.496653c5.088902 3.00545 9.888208 6.615675 14.249539 10.952446l2.215458 2.227738c27.855418 27.820626 27.855418 73.135694 0 101.002368L417.465438 709.790762c-27.854395 27.821649-73.15616 27.821649-101.010555 0l-2.229784-2.204202c-27.854395-27.864628-27.854395-73.204256 0-100.999298l53.771671-53.745065c-9.317203-23.070438-13.763468-47.665603-13.340843-72.140017l-83.176374 83.068927c-51.312666 51.349505-51.312666 135.288243 0 186.563046l2.216481 2.228761c51.299363 51.251268 135.227868 51.251268 186.526207 0l118.835526-118.883621c51.250244-51.299363 51.250244-135.263683 0-186.513928L576.877101 444.959118 576.877101 444.959118 576.877101 444.959118 576.877101 444.959118zM576.877101 444.959118" data-v-2ed5a48c></path></svg> <span class="label" data-v-2ed5a48c>复制链接</span> <!----></li></ul></div></div></div> <div clearfix class="tools view-pc" data-v-1232ed39><div class="tools-left" data-v-1232ed39><span class="el-icon-time" data-v-1232ed39></span> <span class="time" data-v-1232ed39>
                最近更新时间: 2025-02-22 17:46:38
              </span></div> <div class="tools-right btn-single" data-v-1232ed39><!----> <div class="share" data-v-2ed5a48c data-v-1232ed39><svg width="14" height="14" viewBox="0 0 14 14" fill="black" xmlns="http://www.w3.org/2000/svg" class="icon view-pc" data-v-2ed5a48c><path d="M10.5098 9.61883C10.0229 9.61883 9.58081 9.82108 9.26332 10.1433L5.03722 7.79622C5.16186 7.55634 5.23712 7.28824 5.23712 6.99897C5.23712 6.82729 5.20419 6.66502 5.15951 6.50745L9.32447 3.92052C9.6349 4.20038 10.0418 4.37441 10.4886 4.37441C11.4528 4.37441 12.2383 3.58893 12.2383 2.62471C12.2383 1.66049 11.4528 0.875 10.4886 0.875C9.52437 0.875 8.73888 1.66049 8.73888 2.62471C8.73888 2.82461 8.77886 3.01275 8.84 3.19148L4.71267 5.75254C4.39754 5.44211 3.96482 5.24691 3.48506 5.24691C2.52084 5.24691 1.73535 6.0324 1.73535 6.99662C1.73535 7.96084 2.52084 8.74633 3.48506 8.74633C3.83547 8.74633 4.16236 8.6405 4.43517 8.46176L8.82589 10.9005C8.78356 11.051 8.75534 11.2039 8.75534 11.3662C8.75534 12.3304 9.54083 13.1159 10.505 13.1159C11.4693 13.1159 12.2548 12.3304 12.2548 11.3662C12.2548 10.402 11.474 9.61883 10.5098 9.61883ZM10.4886 1.74985C10.9707 1.74985 11.3634 2.1426 11.3634 2.62471C11.3634 3.10682 10.9707 3.49956 10.4886 3.49956C10.0065 3.49956 9.61373 3.10682 9.61373 2.62471C9.61373 2.1426 10.0065 1.74985 10.4886 1.74985ZM2.61256 6.99897C2.61256 6.51686 3.0053 6.12412 3.48741 6.12412C3.96952 6.12412 4.36226 6.51686 4.36226 6.99897C4.36226 7.48108 3.96952 7.87382 3.48741 7.87382C3.0053 7.87382 2.61256 7.48108 2.61256 6.99897ZM10.5098 12.2434C10.0276 12.2434 9.6349 11.8506 9.6349 11.3685C9.6349 10.8864 10.0276 10.4937 10.5098 10.4937C10.9919 10.4937 11.3846 10.8864 11.3846 11.3685C11.3846 11.853 10.9919 12.2434 10.5098 12.2434Z" data-v-2ed5a48c></path></svg> <i class="icon-share view-wap" data-v-2ed5a48c></i> <span class="label mainLabel" data-v-2ed5a48c>分享文章</span> <div class="share-slider" data-v-2ed5a48c><ul data-v-2ed5a48c><li title="分享文档到微博" data-v-2ed5a48c><svg width="200px" height="179.96px" fill="#cdcdcd" viewBox="0 0 1138 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" class="icon" data-v-2ed5a48c><path d="M914.432 518.144q27.648 21.504 38.912 51.712t9.216 62.976-14.336 65.536-31.744 59.392q-34.816 48.128-78.848 81.92t-91.136 56.32-94.72 35.328-89.6 18.944-75.264 7.68-51.712 1.536-49.152-2.56-68.096-10.24-78.336-21.504-79.872-36.352-74.24-55.296-59.904-78.848q-16.384-29.696-22.016-63.488t-5.632-86.016q0-22.528 7.68-51.2t27.136-63.488 53.248-75.776 86.016-90.112q51.2-48.128 105.984-85.504t117.248-57.856q28.672-10.24 63.488-11.264t57.344 11.264q10.24 11.264 19.456 23.04t12.288 29.184q3.072 14.336 0.512 27.648t-5.632 26.624-5.12 25.6 2.048 22.528q17.408 2.048 33.792-1.536t31.744-9.216 31.232-11.776 33.28-9.216q27.648-5.12 54.784-4.608t49.152 7.68 36.352 22.016 17.408 38.4q2.048 14.336-2.048 26.624t-8.704 23.04-7.168 22.016 1.536 23.552q3.072 7.168 14.848 13.312t27.136 12.288 32.256 13.312 29.184 16.384zM656.384 836.608q26.624-16.384 53.76-45.056t44.032-64 18.944-75.776-20.48-81.408q-19.456-33.792-47.616-57.344t-62.976-37.376-74.24-19.968-80.384-6.144q-78.848 0-139.776 16.384t-105.472 43.008-72.192 60.416-38.912 68.608q-11.264 33.792-6.656 67.072t20.992 62.976 42.496 53.248 57.856 37.888q58.368 25.6 119.296 32.256t116.224 0.512 100.864-21.504 74.24-33.792zM522.24 513.024q20.48 8.192 38.912 18.432t32.768 27.648q10.24 12.288 17.92 30.72t10.752 39.424 1.536 42.496-9.728 38.912q-8.192 18.432-19.968 37.376t-28.672 35.328-40.448 29.184-57.344 18.944q-61.44 11.264-117.76-11.264t-88.064-74.752q-12.288-39.936-13.312-70.656t16.384-66.56q13.312-27.648 40.448-51.712t62.464-38.912 75.264-17.408 78.848 12.8zM359.424 764.928q37.888 3.072 57.856-18.432t21.504-48.128-15.36-47.616-52.736-16.896q-27.648 3.072-43.008 23.552t-17.408 43.52 9.728 42.496 39.424 21.504zM778.24 6.144q74.752 0 139.776 19.968t113.664 57.856 76.288 92.16 27.648 122.88q0 33.792-16.384 50.688t-35.328 17.408-35.328-14.336-16.384-45.568q0-40.96-22.528-77.824t-59.392-64.512-84.48-43.52-96.768-15.872q-31.744 0-47.104-15.36t-14.336-34.304 18.944-34.304 51.712-15.36zM778.24 169.984q95.232 0 144.384 48.64t49.152 146.944q0 30.72-10.24 43.52t-22.528 11.264-22.528-14.848-10.24-35.84q0-60.416-34.816-96.256t-93.184-35.84q-19.456 0-28.672-10.752t-9.216-23.04 9.728-23.04 28.16-10.752z" data-v-2ed5a48c></path></svg> <!----> <!----> <span class="label" data-v-2ed5a48c>新浪微博</span> <!----></li><li title="" data-v-2ed5a48c><!----> <svg t="1654592149516" fill="#cdcdcd" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6040" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200" class="icon" data-v-2ed5a48c><path d="M664.250054 368.541681c10.015098 0 19.892049 0.732687 29.67281 1.795902-26.647917-122.810047-159.358451-214.077703-310.826188-214.077703-169.353083 0-308.085774 114.232694-308.085774 259.274068 0 83.708494 46.165436 152.460344 123.281791 205.78483l-30.80868 91.730191 107.688651-53.455469c38.558178 7.53665 69.459978 15.308661 107.924012 15.308661 9.66308 0 19.230993-0.470721 28.752858-1.225921-6.025227-20.36584-9.521864-41.723264-9.521864-63.862493C402.328693 476.632491 517.908058 368.541681 664.250054 368.541681zM498.62897 285.87389c23.200398 0 38.557154 15.120372 38.557154 38.061874 0 22.846334-15.356756 38.156018-38.557154 38.156018-23.107277 0-46.260603-15.309684-46.260603-38.156018C452.368366 300.994262 475.522716 285.87389 498.62897 285.87389zM283.016307 362.090758c-23.107277 0-46.402843-15.309684-46.402843-38.156018 0-22.941502 23.295566-38.061874 46.402843-38.061874 23.081695 0 38.46301 15.120372 38.46301 38.061874C321.479317 346.782098 306.098002 362.090758 283.016307 362.090758zM945.448458 606.151333c0-121.888048-123.258255-221.236753-261.683954-221.236753-146.57838 0-262.015505 99.348706-262.015505 221.236753 0 122.06508 115.437126 221.200938 262.015505 221.200938 30.66644 0 61.617359-7.609305 92.423993-15.262612l84.513836 45.786813-23.178909-76.17082C899.379213 735.776599 945.448458 674.90216 945.448458 606.151333zM598.803483 567.994292c-15.332197 0-30.807656-15.096836-30.807656-30.501688 0-15.190981 15.47546-30.477129 30.807656-30.477129 23.295566 0 38.558178 15.286148 38.558178 30.477129C637.361661 552.897456 622.099049 567.994292 598.803483 567.994292zM768.25071 567.994292c-15.213493 0-30.594809-15.096836-30.594809-30.501688 0-15.190981 15.381315-30.477129 30.594809-30.477129 23.107277 0 38.558178 15.286148 38.558178 30.477129C806.808888 552.897456 791.357987 567.994292 768.25071 567.994292z" p-id="6041" data-v-2ed5a48c></path></svg> <!----> <span class="label" data-v-2ed5a48c>微信</span> <div class="qrcode" data-v-2ed5a48c><div class="note" data-v-2ed5a48c>扫码分享</div> <canvas id="qrcodeCanvas" class="can" data-v-2ed5a48c></canvas> <span class="arrow" data-v-2ed5a48c></span></div></li><li title="复制链接到剪贴板" data-v-2ed5a48c><!----> <!----> <svg fill="#cdcdcd" width="200px" height="200.00px" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" class="icon" data-v-2ed5a48c><path d="M752.535797 273.701662l-2.230808-2.227738c-51.299363-51.300386-135.227868-51.300386-186.526207 0l-118.846782 118.883621c-51.299363 51.281967-51.299363 135.222751 0 186.544627l2.192945 2.156106c4.27742 4.267187 8.833179 8.116865 13.485129 11.728112l43.49563-43.544749c-5.086855-2.956332-9.885138-6.591115-14.223956-10.92891l-2.192945-2.156106c-27.855418-27.866674-27.855418-73.180719 0-101.048417L606.609263 314.26859c27.782763-27.855418 73.084529-27.855418 100.951203 0l2.218528 2.180666c27.855418 27.867698 27.855418 73.194022 0 101.012601l-53.736878 53.765531c9.304923 23.067368 13.740956 47.64002 13.304004 72.114434l83.152838-83.117023C803.83516 408.918273 803.83516 325.004095 752.535797 273.701662L752.535797 273.701662 752.535797 273.701662 752.535797 273.701662zM576.877101 444.959118c-4.266164-4.264117-8.820899-8.118911-13.521968-11.680017l-43.472094 43.496653c5.088902 3.00545 9.888208 6.615675 14.249539 10.952446l2.215458 2.227738c27.855418 27.820626 27.855418 73.135694 0 101.002368L417.465438 709.790762c-27.854395 27.821649-73.15616 27.821649-101.010555 0l-2.229784-2.204202c-27.854395-27.864628-27.854395-73.204256 0-100.999298l53.771671-53.745065c-9.317203-23.070438-13.763468-47.665603-13.340843-72.140017l-83.176374 83.068927c-51.312666 51.349505-51.312666 135.288243 0 186.563046l2.216481 2.228761c51.299363 51.251268 135.227868 51.251268 186.526207 0l118.835526-118.883621c51.250244-51.299363 51.250244-135.263683 0-186.513928L576.877101 444.959118 576.877101 444.959118 576.877101 444.959118 576.877101 444.959118zM576.877101 444.959118" data-v-2ed5a48c></path></svg> <span class="label" data-v-2ed5a48c>复制链接</span> <!----></li></ul></div></div></div></div></div></div> <div class="note" data-v-1232ed39><span data-v-1232ed39>本节先简要介绍DeepSeek的基本信息，接着详述了如何在GPU云主机中运行deepseek-r1-7b模型，最后对不同模型的硬件配置进行推荐。</span></div> <div id="feedback-page" pageId="10955476" class="page-content" data-v-c391fb28 data-v-1232ed39><div editorType="md" class="tplContent" data-v-fd02c5fc data-v-c391fb28><div id="mdContent" class="md" data-v-fd02c5fc><h1>什么是DeepSeek</h1>
<p>DeepSeek 是一个基于 Transformer 架构的大型语言模型（LLM），由深度求索（DeepSeek）公司开发。它能够处理自然语言理解、生成、翻译、问答等多种任务。在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。在对话模型典型任务方面的评测效果如下：</p>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/a43947173a584943b2f677bfc497c9cb" alt="1738851911104.jpg" /></p>
<p>当前 DeepSeek 模型有多个版本，参数量从 1.5B、70B到671B不等，适用于不同的应用场景和计算资源。参数量越多，资源消耗越多，使用者可以根据自己实际需求选择不同模型版本。</p>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><ul originoriginoriginstyle="list-style-type: disc;"><li><p>为维护良好的网络环境和公共秩序，禁止任何用户或机构利用天翼云平台从事违法活动、传播不良信息或实施违反社会公序良俗的行为。若发生此类行为，天翼云将依法采取必要措施，停止相关服务功能，并依法追究责任。</p></li><li><p>模型由DeepSeek公司提供，模型的结果仅供参考，并可能因不同的环境、数据或操作条件而有所不同，我们不对模型的任何结果负责。</p></li></ul></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<h1>快速体验DeepSeek</h1>
<p>Ollama 是一个专为本地运行大语言模型（LLMs）而设计的工具，支持多种模型格式，并提供了简单易用的命令行接口。这里，我们以DeepSeek-r1-7b模型为例，讲解如何在天翼云使用Ollama运行 DeepSeek模型，读者可以根据自己实际需求修改云主机模型和云主机配置。</p>
<h2>步骤一：创建GPU云主机</h2>
<h3>1. 进入创建云主机页面</h3>
<p>a.点击天翼云门户首页的“控制中心”，输入登录的用户名和密码，进入控制中心页面。</p>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/5c66eb2a02bb4e77b2cf0b426f7ede5b" alt="1738892979623.png" /></p>
<p>b.单击“产品服务列表&gt;弹性云主机”，进入主机列表页。</p>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/7995f7ee8638424fa4504648f846526b" alt="企业微信截图_17388930438795.png" /></p>
<p>c.单击“创建云主机”，进入弹性云主机创建页。</p>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/d462cbeabfec46fd9facc31fd5c380c0" alt="1738893095341.png" /></p>
<h3>2. 进行基础配置</h3>
<p>a.根据业务需求配置“计费模式”、“地域”、“企业项目”、“虚拟私有云”、“实例名称”、“主机名称”等。</p>
<p>b.选择规格。此处选择&quot;CPU架构&quot;为&quot;X86&quot;、&quot;分类&quot;为&quot;GPU型&quot;、&quot;规格族&quot;为&quot;GPU计算加速型pi7&quot;、&quot;规格&quot;为&quot;pi7.4xlarge.4&quot;。</p>
<p><img src="" alt="" /><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/80f6fd1ad0d648bcb451a5b5c6cb2387" alt="1738852050141.jpg" /></p>
<p>c.选择镜像。“镜像类型”选择“镜像市场”，在云镜像市场中选择预置了DeepSeek R1模型的DeepSeek-R1-7B-Ubuntu22.04镜像。</p>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><p>本镜像推荐配置：内存≥8G、显存≥16G。</p></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/780adb6bb0df4d98958b8b6fd16ef737" alt="1739418523050.png" /></p>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><p>目前也提供了预装DeepSeek-R1-70B模型的镜像，如您有需求，也可在云镜像市场中进行选择。</p></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<p>d.设置云盘类型和大小。</p>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/0a8a9cd6cfc149d7bcdf667a329b3023" alt="1738893232292.png" /></p>
<h3>3. 网络及高级配置</h3>
<p>设置网络，包括&quot;网卡&quot;、&quot;安全组&quot;，同时配备 &quot;弹性IP&quot; 用于下载和访问模型；设置高级配置，包括&quot;登录方式&quot;、&quot;云主机组&quot;、&quot;用户数据&quot;。</p>
<h3>4. 确认并支付</h3>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/c719957b83e14a3087d11c956c466cb5" alt="1738893404645.png" /></p>
<h2>步骤二：使用DeepSeek模型</h2>
<h3>1. 通过web界面进行模型交互</h3>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><p class="p1" originoriginoriginstyle="margin-top: 0px; margin-bottom: 0px; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; font-size-adjust: none; font-kerning: auto; font-optical-sizing: auto; font-feature-settings: normal; font-variation-settings: normal; font-variant-position: normal; font-variant-emoji: normal; font-stretch: normal; font-size: 12px; line-height: normal; font-family: Helvetica; text-wrap-mode: wrap;">镜像自带的 ollama 工具监听 127.0.0.1:11434、webui 监听 0.0.0.0:3000 端口，云主机默认不对外开放任何端口访问，请按需开放端口访问规则，避免数据泄露。</p><p><br/></p></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<p>a. 放行云主机安全组的 3000 端口。具体操作请参考<a href="https://www.ctyun.cn/document/10026730/10225510">添加安全组规则-弹性云主机-用户指南-安全-安全组-配置安全组规则 - 天翼云</a>。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/616671a5a0e643059bc9892460e55c3e" alt="1738893714254.png" /></p>
<p>b. 访问DeepSeek模型的可视化界面。登录地址为：http://{公网ip地址}:3000。</p>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><p><span originoriginstyle="text-wrap-mode: wrap;">云主机全自动安装DeepSeek模型和可视化界面，请等待云主机启动 5 分钟后，再访问登录界面。</span></p></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<p>首次登录页面如下：</p>
<p><img src="" alt="" /><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/5d30beec85254054861ab7d489a08cb8" alt="1738894091480.png" /></p>
<p><img src="" alt="" />c.注册管理员账号。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/767c35ce63a54d909504e6fea55f9e1b" alt="1738894173946.png" /></p>
<p>d.使用设置。</p>
<p>刷新进入首页，在模型下拉列表中，选择刚部署的DeepSeek:7b 模型。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/75011cbabe5247768ec8931d28099062" alt="1738894336484.png" /></p>
<p>点击左下角进入设置页面，如果您不想开放其他用户注册使用，则需要关闭 “允许用户注册” 功能。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/081e066c136a40e9b89d62896eafefd9" alt="image.png" /></p>
<p>如果您允许用户注册，还可以设置用户注册之后的行为，例如选择新用户注册后默认用户角色为“用户”/“待激活” 等，需要管理员手动激活。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/ccf94123710e496abd6ec94d9641fb9f" alt="1738894562346.png" /></p>
<p>设置模型可见性。多用户模式下，建议把模型设置为&quot;Public&quot;。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/4d6fbf1692354b729e923bf6bfe4a171" alt="1738894666983.png" /></p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/2d864ac70fe74c6abc57756859be436d" alt="1738894690520.png" /></p>
<p>e.使用DeepSeek模型进行模型推理。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/f0170994eaf6404da3ab7eee5ae497d3" alt="1738895357384.png" /></p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/c7bfec839dbc485faeece54a90011bd9" alt="1738894967875.png" /></p>
<h1>自定义部署DeepSeek</h1>
<h2>步骤一：规格选型</h2>
<p>不同版本的模型参数量不同，参数量越多，资源消耗越多。不同规模的企业、客户有不同诉求，客户可根据自己的实际需求，选择所需镜像和模型版本。参数较少的DeepSeek模型可以在CPU上正常运行、如1.5B、7B模型，更大的模型需要GPU才能获得良好的体验。天翼云提供了不同模型的硬件配置建议，如下：</p>
<pre class="mergeTable" onmouseenter="onMTMouseenter()" onmouseleave="onMTMouseleave()"><div><table cellpadding="0" cellspacing="0" width="495" height="224" data-sort="sortDisabled"><colgroup><col width="165" style="width:82.50pt;" span="6"/></colgroup><tbody><tr height="28" style="height:14.00pt;"><td rowspan="2" class="et2" height="28" width="82" x:str="" style="word-break: break-all; text-align: center;"><strong>模型</strong></td><td colspan="5" class="et2" x:str="" style="word-break: break-all; text-align: center;" rowspan="1"><strong>推荐显卡数</strong></td></tr><tr height="28" style="height:14.00pt;"><td class="et2" x:str="" style="text-align: center;"><strong>T4</strong></td><td class="et2" x:str="" style="word-break: break-all; text-align: center;"><strong>V100</strong></td><td class="et2" x:str="" style="text-align: center;"><strong>V100S</strong></td><td class="et2" x:str="" style="text-align: center;"><strong>A10</strong></td><td class="et2" x:str="" style="text-align: center;"><strong>A100</strong></td></tr><tr height="28" style="height:14.00pt;"><td class="et4" height="14" x:str="" style="text-align: center;">DeepSeek-R1-1.5B</td><td class="et4" x:str="" style="text-align: center;">1卡16G（1*16G）</td><td class="et4" x:str="" style="text-align: center;">1卡32G（1*32G）</td><td class="et4" x:str="" style="text-align: center;">1卡32G（1*32G）</td><td class="et4" x:str="" style="text-align: center;">1卡24G（1*24G）</td><td class="et4" x:str="" style="text-align: center;">1卡40G（1*40G）</td></tr><tr height="28" style="height:14.00pt;"><td class="et5" height="14" x:str="" style="text-align: center;">DeepSeek-R1-7B</td><td class="et5" x:str="" style="word-break: break-all; text-align: center;">2卡32G（2*16G）</td><td class="et5" x:str="" style="text-align: center;">1卡32G（1*32G）</td><td class="et5" x:str="" style="text-align: center;">1卡32G（1*32G）</td><td class="et5" x:str="" style="text-align: center;">1卡24G（1*24G）</td><td class="et5" x:str="" style="text-align: center;">1卡40G（1*40G）</td></tr><tr height="28" style="height:14.00pt;"><td class="et4" height="14" x:str="" style="text-align: center;">DeepSeek-R1-8B</td><td class="et4" x:str="" style="text-align: center;">2卡32G（2*16G）</td><td class="et4" x:str="" style="text-align: center;">1卡32G（1*32G）</td><td class="et4" x:str="" style="text-align: center;">1卡32G（1*32G）</td><td class="et4" x:str="" style="text-align: center;">1卡24G（1*24G）</td><td class="et4" x:str="" style="text-align: center;">1卡40G（1*40G）</td></tr><tr height="28" style="height:14.00pt;"><td class="et4" height="14" x:str="" style="text-align: center;">DeepSeek-R1-14B</td><td class="et4" x:str="" style="text-align: center;">4卡64G（4*16G）</td><td class="et4" x:str="" style="text-align: center;">2卡64G（2*32G）</td><td class="et4" x:str="" style="text-align: center;">2卡64G（2*32G）</td><td class="et4" x:str="" style="text-align: center;">2卡48G（2*24G）</td><td class="et4" x:str="" style="text-align: center;">2卡80G（2*40G）</td></tr><tr height="28" style="height:14.00pt;"><td class="et4" height="14" x:str="" style="text-align: center;">DeepSeek-R1-32B</td><td class="et4" x:str="" style="text-align: center;">-</td><td class="et4" x:str="" style="text-align: center; word-break: break-all;">4卡128G（4*32G）</td><td class="et4" x:str="" style="text-align: center; word-break: break-all;">4卡128G（4*32G）</td><td class="et4" x:str="" style="text-align: center;">4卡96G（4*24G）</td><td class="et4" x:str="" style="text-align: center; word-break: break-all;">4卡160G（4*40G）</td></tr><tr height="28" style="height:14.00pt;"><td class="et4" height="14" x:str="" style="text-align: center;">DeepSeek-R1-70B</td><td class="et4" x:str="" style="text-align: center;">-</td><td class="et4" x:str="" style="text-align: center;">-</td><td class="et4" x:str="" style="text-align: center;">-</td><td class="et4" x:str="" style="text-align: center;">-</td><td class="et4" x:str="" style="text-align: center;">4卡160G（4*40G）</td></tr></tbody></table><p style="text-align: center;"><br/></p></div><span><svg class="editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></span></pre>
<p>对应的GPU云主机规格请参见<a href="https://www.ctyun.cn/document/10029787/10348867">NVIDIA GPU云主机-GPU云主机-产品简介-产品规格 - 天翼云</a>。</p>
<h2>步骤二：云主机开通</h2>
<p><a href="https://www.ctyun.cn/document/10026730/10028702">创建弹性云主机-弹性云主机-快速入门 - 天翼云</a></p>
<p><a href="https://www.ctyun.cn/document/10029787/10195732">创建配备GPU驱动的GPU云主机（Linux）-GPU云主机-用户指南-创建GPU云主机 - 天翼云</a></p>
<h2>步骤三：手动部署DeepSeek</h2>
<h3>1. 安装ollama</h3>
<p>a. 下载安装脚本</p>
<p>使用非天翼云DeepSeek镜像时，需要手动安装ollama，这里以 amd64 为例，将如下脚本保存到本地，命名为 install_ollama.sh。</p>
<pre><code>#!/bin/sh
# This script installs Ollama on Linux.
# It detects the current operating system architecture and installs the appropriate version of Ollama.

set -eu

red=&quot;$( (/usr/bin/tput bold || :; /usr/bin/tput setaf 1 || :) 2&gt;&amp;-)&quot;
plain=&quot;$( (/usr/bin/tput sgr0 || :) 2&gt;&amp;-)&quot;

status() { echo &quot;&gt;&gt;&gt; $*&quot; &gt;&amp;2; }
error() { echo &quot;${red}ERROR:${plain} $*&quot;; exit 1; }
warning() { echo &quot;${red}WARNING:${plain} $*&quot;; }

TEMP_DIR=$(mktemp -d)
cleanup() { rm -rf $TEMP_DIR; }
trap cleanup EXIT

available() { command -v $1 &gt;/dev/null; }
require() {
    local MISSING=''
    for TOOL in $*; do
        if ! available $TOOL; then
            MISSING=&quot;$MISSING $TOOL&quot;
        fi
    done

    echo $MISSING
}

[ &quot;$(uname -s)&quot; = &quot;Linux&quot; ] || error 'This script is intended to run on Linux only.'

ARCH=$(uname -m)
case &quot;$ARCH&quot; in
    x86_64) ARCH=&quot;amd64&quot; ;;
    aarch64|arm64) ARCH=&quot;arm64&quot; ;;
    *) error &quot;Unsupported architecture: $ARCH&quot; ;;
esac

IS_WSL2=false

KERN=$(uname -r)
case &quot;$KERN&quot; in
    *icrosoft*WSL2 | *icrosoft*wsl2) IS_WSL2=true;;
    *icrosoft) error &quot;Microsoft WSL1 is not currently supported. Please use WSL2 with 'wsl --set-version &lt;distro&gt; 2'&quot; ;;
    *) ;;
esac

VER_PARAM=&quot;${OLLAMA_VERSION:+?version=$OLLAMA_VERSION}&quot;

SUDO=
if [ &quot;$(id -u)&quot; -ne 0 ]; then
    # Running as root, no need for sudo
    if ! available sudo; then
        error &quot;This script requires superuser permissions. Please re-run as root.&quot;
    fi

    SUDO=&quot;sudo&quot;
fi

NEEDS=$(require curl awk grep sed tee xargs)
if [ -n &quot;$NEEDS&quot; ]; then
    status &quot;ERROR: The following tools are required but missing:&quot;
    for NEED in $NEEDS; do
        echo &quot;  - $NEED&quot;
    done
    exit 1
fi

for BINDIR in /usr/local/bin /usr/bin /bin; do
    echo $PATH | grep -q $BINDIR &amp;&amp; break || continue
done
OLLAMA_INSTALL_DIR=$(dirname ${BINDIR})

if [ -d &quot;$OLLAMA_INSTALL_DIR/lib/ollama&quot; ] ; then
    status &quot;Cleaning up old version at $OLLAMA_INSTALL_DIR/lib/ollama&quot;
    $SUDO rm -rf &quot;$OLLAMA_INSTALL_DIR/lib/ollama&quot;
fi
status &quot;Installing ollama to $OLLAMA_INSTALL_DIR&quot;
$SUDO install -o0 -g0 -m755 -d $BINDIR
$SUDO install -o0 -g0 -m755 -d &quot;$OLLAMA_INSTALL_DIR&quot;
status &quot;Downloading Linux ${ARCH} bundle&quot;
curl --fail --show-error --location --progress-bar \
    &quot;https://mirrors.ctyun.cn/ollama/v0.5.7/ollama-linux-${ARCH}.tgz${VER_PARAM}&quot; | \
    $SUDO tar -xzf - -C &quot;$OLLAMA_INSTALL_DIR&quot;
if [ &quot;$OLLAMA_INSTALL_DIR/bin/ollama&quot; != &quot;$BINDIR/ollama&quot; ] ; then
    status &quot;Making ollama accessible in the PATH in $BINDIR&quot;
    $SUDO ln -sf &quot;$OLLAMA_INSTALL_DIR/ollama&quot; &quot;$BINDIR/ollama&quot;
fi

# Check for NVIDIA JetPack systems with additional downloads
if [ -f /etc/nv_tegra_release ] ; then
    if grep R36 /etc/nv_tegra_release &gt; /dev/null ; then
        status &quot;Downloading JetPack 6 components&quot;
        curl --fail --show-error --location --progress-bar \
            &quot;https://mirrors.ctyun.cn/ollama/v0.5.7/ollama-linux-${ARCH}-jetpack6.tgz${VER_PARAM}&quot; | \
            $SUDO tar -xzf - -C &quot;$OLLAMA_INSTALL_DIR&quot;
    elif grep R35 /etc/nv_tegra_release &gt; /dev/null ; then
        status &quot;Downloading JetPack 5 components&quot;
        curl --fail --show-error --location --progress-bar \
            &quot;https://mirrors.ctyun.cn/ollama/v0.5.7/ollama-linux-${ARCH}-jetpack5.tgz${VER_PARAM}&quot; | \
            $SUDO tar -xzf - -C &quot;$OLLAMA_INSTALL_DIR&quot;
    else
        warning &quot;Unsupported JetPack version detected.  GPU may not be supported&quot;
    fi
fi

install_success() {
    status 'The Ollama API is now available at 127.0.0.1:11434.'
    status 'Install complete. Run &quot;ollama&quot; from the command line.'
}
trap install_success EXIT

# Everything from this point onwards is optional.

configure_systemd() {
    if ! id ollama &gt;/dev/null 2&gt;&amp;1; then
        status &quot;Creating ollama user...&quot;
        $SUDO useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
    fi
    if getent group render &gt;/dev/null 2&gt;&amp;1; then
        status &quot;Adding ollama user to render group...&quot;
        $SUDO usermod -a -G render ollama
    fi
    if getent group video &gt;/dev/null 2&gt;&amp;1; then
        status &quot;Adding ollama user to video group...&quot;
        $SUDO usermod -a -G video ollama
    fi

    status &quot;Adding current user to ollama group...&quot;
    $SUDO usermod -a -G ollama $(whoami)

    status &quot;Creating ollama systemd service...&quot;
    cat &lt;&lt;EOF | $SUDO tee /etc/systemd/system/ollama.service &gt;/dev/null
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=$BINDIR/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment=&quot;PATH=$PATH&quot;

[Install]
WantedBy=default.target
EOF
    SYSTEMCTL_RUNNING=&quot;$(systemctl is-system-running || true)&quot;
    case $SYSTEMCTL_RUNNING in
        running|degraded)
            status &quot;Enabling and starting ollama service...&quot;
            $SUDO systemctl daemon-reload
            $SUDO systemctl enable ollama

            start_service() { $SUDO systemctl restart ollama; }
            trap start_service EXIT
            ;;
        *)
            warning &quot;systemd is not running&quot;
            if [ &quot;$IS_WSL2&quot; = true ]; then
                warning &quot;see https://learn.microsoft.com/en-us/windows/wsl/systemd#how-to-enable-systemd to enable it&quot;
            fi
            ;;
    esac
}

if available systemctl; then
    configure_systemd
fi

# WSL2 only supports GPUs via nvidia passthrough
# so check for nvidia-smi to determine if GPU is available
if [ &quot;$IS_WSL2&quot; = true ]; then
    if available nvidia-smi &amp;&amp; [ -n &quot;$(nvidia-smi | grep -o &quot;CUDA Version: [0-9]*\.[0-9]*&quot;)&quot; ]; then
        status &quot;Nvidia GPU detected.&quot;
    fi
    install_success
    exit 0
fi

# Don't attempt to install drivers on Jetson systems
if [ -f /etc/nv_tegra_release ] ; then
    status &quot;NVIDIA JetPack ready.&quot;
    install_success
    exit 0
fi

# Install GPU dependencies on Linux
if ! available lspci &amp;&amp; ! available lshw; then
    warning &quot;Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.&quot;
    exit 0
fi

check_gpu() {
    # Look for devices based on vendor ID for NVIDIA and AMD
    case $1 in
        lspci)
            case $2 in
                nvidia) available lspci &amp;&amp; lspci -d '10de:' | grep -q 'NVIDIA' || return 1 ;;
                amdgpu) available lspci &amp;&amp; lspci -d '1002:' | grep -q 'AMD' || return 1 ;;
            esac ;;
        lshw)
            case $2 in
                nvidia) available lshw &amp;&amp; $SUDO lshw -c display -numeric -disable network | grep -q 'vendor: .* \[10DE\]' || return 1 ;;
                amdgpu) available lshw &amp;&amp; $SUDO lshw -c display -numeric -disable network | grep -q 'vendor: .* \[1002\]' || return 1 ;;
            esac ;;
        nvidia-smi) available nvidia-smi || return 1 ;;
    esac
}

if check_gpu nvidia-smi; then
    status &quot;NVIDIA GPU installed.&quot;
    exit 0
fi

if ! check_gpu lspci nvidia &amp;&amp; ! check_gpu lshw nvidia &amp;&amp; ! check_gpu lspci amdgpu &amp;&amp; ! check_gpu lshw amdgpu; then
    install_success
    warning &quot;No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode.&quot;
    exit 0
fi

if check_gpu lspci amdgpu || check_gpu lshw amdgpu; then
    status &quot;Downloading Linux ROCm ${ARCH} bundle&quot;
    curl --fail --show-error --location --progress-bar \
        &quot;https://mirrors.ctyun.cn/ollama/v0.5.7/ollama-linux-${ARCH}-rocm.tgz${VER_PARAM}&quot; | \
        $SUDO tar -xzf - -C &quot;$OLLAMA_INSTALL_DIR&quot;

    install_success
    status &quot;AMD GPU ready.&quot;
    exit 0
fi

CUDA_REPO_ERR_MSG=&quot;NVIDIA GPU detected, but your OS and Architecture are not supported by NVIDIA.  Please install the CUDA driver manually https://docs.nvidia.com/cuda/cuda-installation-guide-linux/&quot;
# ref: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-7-centos-7
# ref: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-rocky-8
# ref: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-rocky-9
# ref: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#fedora
install_cuda_driver_yum() {
    status 'Installing NVIDIA repository...'

    case $PACKAGE_MANAGER in
        yum)
            $SUDO $PACKAGE_MANAGER -y install yum-utils
            if curl -I --silent --fail --location &quot;https://developer.download.nvidia.com/compute/cuda/repos/$1$2/$(uname -m | sed -e 's/aarch64/sbsa/')/cuda-$1$2.repo&quot; &gt;/dev/null ; then
                $SUDO $PACKAGE_MANAGER-config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$1$2/$(uname -m | sed -e 's/aarch64/sbsa/')/cuda-$1$2.repo
            else
                error $CUDA_REPO_ERR_MSG
            fi
            ;;
        dnf)
            if curl -I --silent --fail --location &quot;https://developer.download.nvidia.com/compute/cuda/repos/$1$2/$(uname -m | sed -e 's/aarch64/sbsa/')/cuda-$1$2.repo&quot; &gt;/dev/null ; then
                $SUDO $PACKAGE_MANAGER config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$1$2/$(uname -m | sed -e 's/aarch64/sbsa/')/cuda-$1$2.repo
            else
                error $CUDA_REPO_ERR_MSG
            fi
            ;;
    esac

    case $1 in
        rhel)
            status 'Installing EPEL repository...'
            # EPEL is required for third-party dependencies such as dkms and libvdpau
            $SUDO $PACKAGE_MANAGER -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-$2.noarch.rpm || true
            ;;
    esac

    status 'Installing CUDA driver...'

    if [ &quot;$1&quot; = 'centos' ] || [ &quot;$1$2&quot; = 'rhel7' ]; then
        $SUDO $PACKAGE_MANAGER -y install nvidia-driver-latest-dkms
    fi

    $SUDO $PACKAGE_MANAGER -y install cuda-drivers
}

# ref: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu
# ref: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#debian
install_cuda_driver_apt() {
    status 'Installing NVIDIA repository...'
    if curl -I --silent --fail --location &quot;https://developer.download.nvidia.com/compute/cuda/repos/$1$2/$(uname -m | sed -e 's/aarch64/sbsa/')/cuda-keyring_1.1-1_all.deb&quot; &gt;/dev/null ; then
        curl -fsSL -o $TEMP_DIR/cuda-keyring.deb https://developer.download.nvidia.com/compute/cuda/repos/$1$2/$(uname -m | sed -e 's/aarch64/sbsa/')/cuda-keyring_1.1-1_all.deb
    else
        error $CUDA_REPO_ERR_MSG
    fi

    case $1 in
        debian)
            status 'Enabling contrib sources...'
            $SUDO sed 's/main/contrib/' &lt; /etc/apt/sources.list | $SUDO tee /etc/apt/sources.list.d/contrib.list &gt; /dev/null
            if [ -f &quot;/etc/apt/sources.list.d/debian.sources&quot; ]; then
                $SUDO sed 's/main/contrib/' &lt; /etc/apt/sources.list.d/debian.sources | $SUDO tee /etc/apt/sources.list.d/contrib.sources &gt; /dev/null
            fi
            ;;
    esac

    status 'Installing CUDA driver...'
    $SUDO dpkg -i $TEMP_DIR/cuda-keyring.deb
    $SUDO apt-get update

    [ -n &quot;$SUDO&quot; ] &amp;&amp; SUDO_E=&quot;$SUDO -E&quot; || SUDO_E=
    DEBIAN_FRONTEND=noninteractive $SUDO_E apt-get -y install cuda-drivers -q
}

if [ ! -f &quot;/etc/os-release&quot; ]; then
    error &quot;Unknown distribution. Skipping CUDA installation.&quot;
fi

. /etc/os-release

OS_NAME=$ID
OS_VERSION=$VERSION_ID

PACKAGE_MANAGER=
for PACKAGE_MANAGER in dnf yum apt-get; do
    if available $PACKAGE_MANAGER; then
        break
    fi
done

if [ -z &quot;$PACKAGE_MANAGER&quot; ]; then
    error &quot;Unknown package manager. Skipping CUDA installation.&quot;
fi

if ! check_gpu nvidia-smi || [ -z &quot;$(nvidia-smi | grep -o &quot;CUDA Version: [0-9]*\.[0-9]*&quot;)&quot; ]; then
    case $OS_NAME in
        centos|rhel) install_cuda_driver_yum 'rhel' $(echo $OS_VERSION | cut -d '.' -f 1) ;;
        rocky) install_cuda_driver_yum 'rhel' $(echo $OS_VERSION | cut -c1) ;;
        fedora) [ $OS_VERSION -lt '39' ] &amp;&amp; install_cuda_driver_yum $OS_NAME $OS_VERSION || install_cuda_driver_yum $OS_NAME '39';;
        amzn) install_cuda_driver_yum 'fedora' '37' ;;
        debian) install_cuda_driver_apt $OS_NAME $OS_VERSION ;;
        ubuntu) install_cuda_driver_apt $OS_NAME $(echo $OS_VERSION | sed 's/\.//') ;;
        *) exit ;;
    esac
fi

if ! lsmod | grep -q nvidia || ! lsmod | grep -q nvidia_uvm; then
    KERNEL_RELEASE=&quot;$(uname -r)&quot;
    case $OS_NAME in
        rocky) $SUDO $PACKAGE_MANAGER -y install kernel-devel kernel-headers ;;
        centos|rhel|amzn) $SUDO $PACKAGE_MANAGER -y install kernel-devel-$KERNEL_RELEASE kernel-headers-$KERNEL_RELEASE ;;
        fedora) $SUDO $PACKAGE_MANAGER -y install kernel-devel-$KERNEL_RELEASE ;;
        debian|ubuntu) $SUDO apt-get -y install linux-headers-$KERNEL_RELEASE ;;
        *) exit ;;
    esac

    NVIDIA_CUDA_VERSION=$($SUDO dkms status | awk -F: '/added/ { print $1 }')
    if [ -n &quot;$NVIDIA_CUDA_VERSION&quot; ]; then
        $SUDO dkms install $NVIDIA_CUDA_VERSION
    fi

    if lsmod | grep -q nouveau; then
        status 'Reboot to complete NVIDIA CUDA driver install.'
        exit 0
    fi

    $SUDO modprobe nvidia
    $SUDO modprobe nvidia_uvm
fi

# make sure the NVIDIA modules are loaded on boot with nvidia-persistenced
if available nvidia-persistenced; then
    $SUDO touch /etc/modules-load.d/nvidia.conf
    MODULES=&quot;nvidia nvidia-uvm&quot;
    for MODULE in $MODULES; do
        if ! grep -qxF &quot;$MODULE&quot; /etc/modules-load.d/nvidia.conf; then
            echo &quot;$MODULE&quot; | $SUDO tee -a /etc/modules-load.d/nvidia.conf &gt; /dev/null
        fi
    done
fi

status &quot;NVIDIA GPU ready.&quot;
install_success
</code></pre>
<p>b. 执行安装</p>
<pre><code>bash install_ollama.sh
</code></pre>
<p>如下显示则为安装成功。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/4a5084f20489445e9d38179e70067045" alt="1739012312125.png" /></p>
<p>c.测试ollama服务安装情况</p>
<pre><code>ollama ps
</code></pre>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/86087e7fa681420e99ba63cdcfd14793" alt="1739012369474.png" /></p>
<p><strong>2. 下载模型</strong></p>
<p>天翼云<a href="https://mirrors.ctyun.cn/ollama/models/">镜像站</a>也为常见镜像提供了加速能力，包括1.5B\7B\14B\70B\671B 等相关模型，可以通过如下手段体验其他模型，以14B 模型为例：</p>
<pre><code>mkdir deepseek-r1-14b
cd deepseek-r1-14b
wget https://mirrors.ctyun.cn/ollama/models/deepseek-r1-14b/deepseek-r1-14b.gguf
wget https://mirrors.ctyun.cn/ollama/models/deepseek-r1-14b/ModelFile
ollama create deepseek-r1:14b -f ModelFile
</code></pre>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/dd59dcd1503b4b30891143d8d2e00b8b" alt="1739158672216.jpg" /></p>
<p>如果你想体验其他模型，也可以直接通过ollama下载。</p>
<pre><code>ollama pull deepseek-r1:14b
</code></pre>
<h3>3. 使用ollama运行模型</h3>
<pre><code>ollama run deepseek-r1:14b
</code></pre>
<h3>4.通过web界面进行交互</h3>
<p>a.安装open-webui</p>
<pre><code>docker pull ghcr.io/open-webui/open-webui:main
</code></pre>
<p>b.启动容器</p>
<pre><code>docker run -d --net=host -e PORT=3000 -e 
OLLAMA_BASE_URL=http://127.0.0.1:11434 -e
ENABLE_SIGNUP=true -e ENABLE_OPENAI_API=False -v open-webui:/app/backend/data --name
open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
<p>后续请参考上文“<strong>快速体验DeepSeek——步骤二：使用deepseek模型”</strong>。</p>
<h1>FAQ</h1>
<h2>盘不够了，我应该怎么办？</h2>
<p>如果您在模型部署过程中发现云盘的容量不够，可以采取如下措施:</p>
<p>1.根据<a href="https://www.ctyun.cn/document/10027696/10029073">云硬盘扩容概述-云硬盘-用户指南-扩容云硬盘 - 天翼云</a>对已有云盘进行扩容。</p>
<p>2.新建一块数据盘并挂载，相关操作见<a href="https://www.ctyun.cn/document/10000019/10033591">挂载云硬盘-云硬盘-快速入门 - 天翼云</a>、<a href="https://www.ctyun.cn/document/10000015/10001752">初始化数据盘-弹性云主机-快速入门 - 天翼云</a>。</p>
<h2>如何修改ollama模型的存储位置？</h2>
<p>在linux环境下，ollama默认模型存储目录是 <code>/usr/share/ollama/.ollama/models/</code>，我们建议您使用云硬盘独立挂载数据盘，将模型存储到数据盘中。模型存储位置是由环境变量控制的，我们需要修改ollama的环境变量重启服务才能修改存储目录，我们以 <code>/data/ollama/models</code> 目录为例：</p>
<p>1.打开 <code>ollama.service</code> 文件</p>
<pre><code>vi /etc/systemd/system/ollama.service
</code></pre>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><p class="paragraph text-align-type-justify" originoriginstyle="margin: 4px 0;text-align: justify;font-family: 等线;font-size: 16px"><span data-font-family="微软雅黑" originoriginstyle="font-size: 15px;font-family: 微软雅黑;font-weight: bold;color: #333333;letter-spacing: 0;vertical-align: baseline">请确保 ollama 用户组中的 ollama 用户具备访问该目录的读写权限</span></p><p><br/></p></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<p>2.新增相关环境变量</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/33a3bcbeca604c76870a0d8f1167269f" alt="2.png" /></p>
<p>3.重启服务</p>
<pre><code>systemctl daemon-reload
systemctl restart ollama
</code></pre>
<h2>如何通过vllm部署模型？</h2>
<p>建议使用天翼云提供的DeepSeek镜像，减少安装过程中可能遇到的问题。如您必须通过vllm部署模型，请参考如下步骤：</p>
<p>1.安装依赖包</p>
<pre><code># 安装pip
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python get-pip.py
# 修改pip镜像源，以清华源为例
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

# 安装依赖包
pip install modelscope==1.22.3
pip install openai==1.61.0
pip install tqdm==4.67.1
pip install transformers==4.48.2
pip install vllm==0.7.1
pip install jinja2==3.1.0
</code></pre>
<p>2.下载模型</p>
<p>为了方便，我们以较小的DeepSeek-R1-Distill-Qwen-1.5B为例（3.5G左右），将以下内容保存为 model_download.py 文件，<strong>参数 cache_dir 为模型的下载路径，您可以按需修改，需确保存储空间足够存放模型。</strong></p>
<pre><code>from modelscope import snapshot_download
model_dir = snapshot_download('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', cache_dir='/root/model-path', revision='master')
</code></pre>
<p>运行该文件，启动模型下载。</p>
<pre><code>python model_download.py
</code></pre>
<p>3.运行模型</p>
<p>完成下载后，即可使用 vllm 运行模型。</p>
<pre><code>vllm serve
/root/model-path/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B   
--served-model-name DeepSeek-R1-Distill-Qwen-1.5B   
--max-model-len=2048 --api-key my-token --port=8000
</code></pre>
<pre class="mergeHeightLight"><div class="heightLight heightLight-zhuyi"><div class="heightLight-p1"><i class="icon"></i>注意</div><div class="heightLight-p2"><p>其中 --api-key 参数用于模型 api 调用时认证动作，可按需修改值。</p></div><svg class="heightLight-editBtn"><use class="editUse" xlink:href="#vditor-icon-edit"></use></svg></div></pre>
<p>4.使用WebUI访问模型</p>
<p>基于我们已经安装、配置好的 OpenWebUI页面，可以直接访问模型。</p>
<p>管理员设置中，配置OpenAI API访问地址，密钥就是上文中的 --api-key。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/bfb8a625641c4484a2e93d9f36f3d81b" alt="1739275580172.png" /></p>
<p>选择对应的模型，直接进行问答体验。</p>
<p><img src="https://ctyun-portal.gdoss.xstore.ctyun.cn/file/28ba622edcd644a081d8171c440e1272" alt="1739275700080.png" /></p>
浏览量:&nbsp;<span id="" class="leancloud_visitors" data-flag-title=""> - </span>次.
    <script src="script.js"></script>
	<!-- 同时兼容http与https -->
<!-- 同时兼容http与https -->
<script src="//cdn1.lncld.net/static/js/2.5.0/av-min.js"></script>
<script>
    // 第一个参数是appid，第二个参数是appkey，此处的只是示例
    AV.initialize("ENBZ1RSuxxVVZnmvZnrJAfrc-gzGzoHsz", "5yQhWWxccGEpBsfcPeQptieH");
    // 自己创建的Class的名字
    var name='Counter';
    function createRecord(Counter){
      // 设置 ACL
      var acl = new AV.ACL();
      acl.setPublicReadAccess(true);
      acl.setPublicWriteAccess(true);
      // 获得span的所有元素
      var elements=document.getElementsByClassName('leancloud_visitors');
      // 一次创建多条记录
      var allcounter=[];
      for (var i = 0; i < elements.length ; i++) {
        // 若某span的内容不包括 '-' ，则不必创建记录
        if(elements[i].textContent.indexOf('-') == -1){
          continue;
        }
        var title = elements[i].getAttribute('data-flag-title');
        var url = elements[i].id;
        var newcounter = new Counter();
        newcounter.setACL(acl);
        newcounter.set("title", title);
        newcounter.set("url", url);
        newcounter.set("time", 0);
        allcounter.push(newcounter);
        // 顺便更新显示span为默认值0
        elements[i].textContent=0;
      }
      AV.Object.saveAll(allcounter).then(function (todo) {
        // 成功保存记录之后
        console.log('创建记录成功！');
      }, function (error) {
        // 异常错误 
        console.error('创建记录失败: ' + error.message);
      });
    }
    function showCount(Counter){
      // 是否需要创建新纪录的标志（添加一篇新文章）
      var flag=false;
      var query = new AV.Query(name);
      query.greaterThanOrEqualTo('time', 0);
      query.find().then(function (results) {
        // 当获取到的记录为0时置默认值
        if(results.length==0){
          $('.leancloud_visitors').text('-');
          flag=true;
          console.log('返回查询记录为空');
          // 如果获取到空记录就创建新记录
          createRecord(Counter);
          return;
        }
        // 将获取到的数据设置为text
        for (var i = 0; i < results.length; i++) {
          var item = results[i];
          var url = item.get('url');
          var time = item.get('time');
          var element = document.getElementById(url);
          element.textContent = time;
        }
        // 当某个span含有默认值时说明需要创建记录
        if($('.leancloud_visitors').text().indexOf("-") != -1){
          flag=true;
        }
        // 当获取的记录数与span个数不吻合时
        if(results.length != $('.leancloud_visitors').length){
          flag=true;
        }
        if(flag){
          createRecord(Counter);
        }
      }, function (error) {
        console.log('query error:'+error.message);
      });
    }
    $(function() {
      var Counter = AV.Object.extend(name);
      showCount(Counter);
    });
</script>
</body>
</html>
